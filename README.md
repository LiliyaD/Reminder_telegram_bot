# Telegram Bot Reminder

## Телеграм бот для записи ежедневных активностей.

Приложение разделено на 2 сервиса: сервис интерфейс и сервис по работе с данными.
Интерфейсная часть осуществляет валидацию данных и передает их дальше.
Сервис работы с данными осуществляет непосредственное сохранение и получение данных.
Общение между сервисами ппроисходит по gRPC. ActivityListStream - потоковый метод для получения списка активностей.
Для упрощение далее в тексте сервис интерфейс будем называть клиентом, а сервис по работе с данными сервером.

### _Доступные команды:_
- /help - перечисление всех команд
- /examples - примеры
- /list, /list_stream - вывести все активности
- /get <name> - получить информацию об активности
- /today - вывести сегодняшнии активности
- /add <name> <begin_date> <end_date> <times_per_day> <quantity_per_time> - добавить новую активность
- /delete <name> - удалить активность
- /update <name> <begin_date> <end_date> <times_per_day> <quantity_per_time> - обновить активность, если какие-то поля не требуется менять, напишите "_" на месте таких параметров

Сервер имеет функции по работе с хранилищем.
В качестве хранилища по умолчанию используется БД PostgreSQL, но можно использовать и только локальный кеш (если вызвать сервер с ключом --local).
Для хранилища реализованы стандартные CRUD операций + возврат списка сохраненных сущностей.
Хранилище данных может работать в многопоточной среде, количество одновременных обращений к хранилищу ограничено до 10.
У хранилища задан контекст и таймауты в 2 секунды, чтобы ожидание свободных воркеров было ограниченно по времени.

Помимо использования телеграм бота, можно просто делать gRPC вызовы или http вызовы со стороны клиента. То есть в качестве клиента выступает не только телеграм бот, но но и gRPC, http интерфейсы. В проект также добавлен gRPC gateway. В проекте также предусмотрен swagger для документации API.
Телеграм бот в свою очередь использует gRPC, чтобы получить данные от сервера.

Что сделано дополнительно для PostgreSQL:
- Добавлены идемпотентные миграции с инициализацией таблиц.
- Добавлены параметры для пагинации (limit, offset, order).
- Доступ к PostgreSQL осуществляется через пул соединений (pgbouncer).

Так же общение сервисов реализовано через брокер сообщений Kafka, вместо gRPC для части операций (в этом нет необходимости, просто хотелось познакомиться с Kafka). Для реализации использовался паттерн Producer/Consumer. Producer отправляет данные из сервиса-клиента в Kafka. Consumer на стороне сервера слушает, не пришло ли что-то в Kafka и исполяет одну из CRUD операций, в зависимости от топика сообщения. Эту реализацию можно увидеть в commands_kafka.go, до того как CRUD операции были изменены для Kafka, для них использовался gRPC вызов сервисной части работы с данными, эту реализацию можно увидеть в commands_grpc.go.

Добавлена работа с кешем с помощью Redis для более быстрого получения данных на серевере работы с данными. Перед попыткой считать и добавить запись в БД, сначала проверяется кеш. Если в нём есть такие данные, выдается результат, иначе проверяется БД. При успешном чтении записи из БД, она добавляется в кеш. При обновлении и удалении записи в БД, запись также удаляется из кеша.
Для получения ответов по CRUD операциям, сообщения о которых записывались в Kafka реализован механизм оповещения с помощью паттерна Publish–subscribe Redis, на стороне сервера Consumer получив и обработав операцию отправляет результат по ней по такому же id в Redis, а методы, которые делали отправку в Kafka слушают(реализовано для удаления)/переодически проверяют(реализовано для создания и обновления) Redis и выдают результат.

Для части кода написаны unit-тесты и интеграционные тесты, сделаны моки для для внешних вызовов (PostgreSQL, gRPC)

Добавлено логгирование, вывод лога в консоль, в логе предусмотрен механизм, чтобы писать его в файл. Есть разделение по уровням логгирования.
Добавлен trace и счетчики для входящих, исходящих, успешных, неудачных запросов и ошибок, а также счетчики hit и miss для работы с кешем.

_Этот проект делался поэтапно в плане изучения языка и новых технологий, поэтому некоторые моменты в коде странные._